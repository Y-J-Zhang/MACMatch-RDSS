***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/StyleMatch/ssdg_officehome_v1.yaml
dataset_config_file: configs/datasets/ssdg_officehome.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['MODEL.BACKBONE.NAME', 'resnet18', 'DATASET.NUM_LABELED', '975']
output_dir: output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5
resume: 
root: ../data
seed: 5
source_domains: ['art', 'clipart', 'product']
target_domains: ['real_world']
trainer: StyleMatch
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: True
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 192
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: SeqDomainSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SSDGOfficeHome
  NUM_LABELED: 975
  NUM_SHOTS: -1
  ROOT: ../data
  SOURCE_DOMAINS: ['art', 'clipart', 'product']
  STL10_FOLD: -1
  TARGET_DOMAINS: ['real_world']
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bilinear
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD: [0.229, 0.224, 0.225]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_flip', 'random_translation', 'normalize')
MODEL:
  BACKBONE:
    NAME: resnet18
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.003
  LR_SCHEDULER: cosine
  MAX_EPOCH: 20
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5
RESUME: 
SEED: 5
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_u
  PRINT_FREQ: 10
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: StyleMatch
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
  STYLEMATCH:
    ADAIN_DECODER: weights/decoder.pth
    ADAIN_VGG: weights/vgg_normalised.pth
    APPLY_AUG: True
    APPLY_STY: True
    CLASSIFIER: stochastic
    CONF_THRE: 0.95
    C_OPTIM:
      ADAM_BETA1: 0.9
      ADAM_BETA2: 0.999
      BASE_LR_MULT: 0.1
      GAMMA: 0.1
      LR: 0.01
      LR_SCHEDULER: cosine
      MAX_EPOCH: 20
      MOMENTUM: 0.9
      NAME: sgd
      NEW_LAYERS: ()
      RMSPROP_ALPHA: 0.99
      SGD_DAMPNING: 0
      SGD_NESTEROV: False
      STAGED_LR: False
      STEPSIZE: (-1,)
      WARMUP_CONS_LR: 1e-05
      WARMUP_EPOCH: -1
      WARMUP_MIN_LR: 1e-05
      WARMUP_RECOUNT: True
      WARMUP_TYPE: linear
      WEIGHT_DECAY: 0.0005
    INFERENCE_MODE: deterministic
    N_ENSEMBLE: 10
    SAVE_SIGMA: False
    STRONG_TRANSFORMS: ('random_flip', 'randaugment_fixmatch', 'normalize', 'cutout')
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1+cu117
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 18.04.5 LTS (x86_64)
GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Clang version: Could not collect
CMake version: version 3.27.0
Libc version: glibc-2.27

Python version: 3.9.17 (main, Jul  5 2023, 20:41:20)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-57-generic-x86_64-with-glibc2.27
Is CUDA available: True
CUDA runtime version: 11.1.105
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A40
Nvidia driver version: 470.161.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.0.5
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.0.5
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.0.5
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.0.5
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.0.5
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.0.5
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.0.5
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              256
On-line CPU(s) list: 0-255
Thread(s) per core:  2
Core(s) per socket:  64
Socket(s):           2
NUMA node(s):        2
Vendor ID:           AuthenticAMD
CPU family:          25
Model:               1
Model name:          AMD EPYC 7763 64-Core Processor
Stepping:            1
CPU MHz:             1500.000
CPU max MHz:         3529.0520
CPU min MHz:         1500.0000
BogoMIPS:            4899.85
Virtualization:      AMD-V
L1d cache:           32K
L1i cache:           32K
L2 cache:            512K
L3 cache:            32768K
NUMA node0 CPU(s):   0-63,128-191
NUMA node1 CPU(s):   64-127,192-255
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.25.1
[pip3] torch==2.0.1
[pip3] torchvision==0.15.2
[conda] numpy                     1.25.1                   pypi_0    pypi
[conda] torch                     2.0.1                    pypi_0    pypi
[conda] torchvision               0.15.2                   pypi_0    pypi
        Pillow (10.0.0)

Loading trainer: StyleMatch
Building transform_train
+ resize to 224x224
+ random translation
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
Building transform_train
+ resize to 224x224
+ random flip
+ randaugment_fixmatch (n=2)
+ to torch tensor of range [0, 1]
+ cutout (n_holes=1, length=16)
+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
Loading dataset: SSDGOfficeHome
Reading split from "/output/data/office_home_dg/splits_ssdg/real_world_nlab975_seed5.json"
* Using custom transform for training
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
---------  -----------------------------
Dataset    SSDGOfficeHome
Source     ['art', 'clipart', 'product']
Target     ['real_world']
# classes  65
# train_x  975
# train_u  9,065
# val      1,191
# test     4,357
---------  -----------------------------
Building G
Backbone: resnet18
# params: 11,176,512
Building C
# params: 66,560
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5/tensorboard)
epoch [1/20] batch [10/28] time 1.515 (2.320) data 0.000 (0.386) loss_x 8.8952 (11.7532) loss_u_aug 0.0000 (0.0000) loss_u_sty 0.0000 (0.0000) y_u_pred_acc_thre 0.0000 (0.0000) y_u_pred_acc_raw 0.2865 (0.1354) y_u_pred_keep_rate 0.0000 (0.0000) lr 3.0000e-03 eta 0:21:15
epoch [1/20] batch [20/28] time 1.508 (2.123) data 0.001 (0.395) loss_x 4.3631 (8.5913) loss_u_aug 0.2154 (0.0650) loss_u_sty 0.4625 (0.1160) y_u_pred_acc_thre 1.0000 (0.4861) y_u_pred_acc_raw 0.4531 (0.2786) y_u_pred_keep_rate 0.0625 (0.0188) lr 3.0000e-03 eta 0:19:06
epoch [2/20] batch [10/28] time 1.526 (1.836) data 0.001 (0.314) loss_x 1.7001 (1.8831) loss_u_aug 0.4038 (0.3359) loss_u_sty 0.5545 (0.5995) y_u_pred_acc_thre 1.0000 (0.9848) y_u_pred_acc_raw 0.5938 (0.5651) y_u_pred_keep_rate 0.1198 (0.1083) lr 2.9815e-03 eta 0:15:58
epoch [2/20] batch [20/28] time 1.524 (1.850) data 0.001 (0.327) loss_x 1.1243 (1.5799) loss_u_aug 0.3816 (0.3675) loss_u_sty 0.7087 (0.6699) y_u_pred_acc_thre 0.9333 (0.9766) y_u_pred_acc_raw 0.6354 (0.5799) y_u_pred_keep_rate 0.1562 (0.1281) lr 2.9815e-03 eta 0:15:47
epoch [3/20] batch [10/28] time 1.514 (1.838) data 0.001 (0.314) loss_x 0.7515 (0.7477) loss_u_aug 0.4456 (0.4845) loss_u_sty 1.0095 (0.8382) y_u_pred_acc_thre 0.9487 (0.9793) y_u_pred_acc_raw 0.5938 (0.6141) y_u_pred_keep_rate 0.2031 (0.1698) lr 2.9266e-03 eta 0:15:08
epoch [3/20] batch [20/28] time 1.515 (1.859) data 0.001 (0.338) loss_x 0.5449 (0.6515) loss_u_aug 0.6815 (0.5348) loss_u_sty 0.9467 (0.8791) y_u_pred_acc_thre 0.9487 (0.9735) y_u_pred_acc_raw 0.6042 (0.6174) y_u_pred_keep_rate 0.2031 (0.1813) lr 2.9266e-03 eta 0:14:59
epoch [4/20] batch [10/28] time 1.509 (1.834) data 0.001 (0.318) loss_x 0.3247 (0.4015) loss_u_aug 0.5645 (0.6038) loss_u_sty 1.0353 (1.0282) y_u_pred_acc_thre 0.9211 (0.9473) y_u_pred_acc_raw 0.5573 (0.5927) y_u_pred_keep_rate 0.1979 (0.2286) lr 2.8365e-03 eta 0:14:14
epoch [4/20] batch [20/28] time 1.532 (1.860) data 0.001 (0.342) loss_x 0.3466 (0.3816) loss_u_aug 0.4871 (0.5949) loss_u_sty 0.8020 (1.0159) y_u_pred_acc_thre 0.9767 (0.9633) y_u_pred_acc_raw 0.6198 (0.6102) y_u_pred_keep_rate 0.2240 (0.2297) lr 2.8365e-03 eta 0:14:08
epoch [5/20] batch [10/28] time 1.532 (1.871) data 0.001 (0.346) loss_x 0.3150 (0.2657) loss_u_aug 0.6709 (0.6972) loss_u_sty 0.9114 (1.0886) y_u_pred_acc_thre 0.8627 (0.9368) y_u_pred_acc_raw 0.6094 (0.6323) y_u_pred_keep_rate 0.2656 (0.2714) lr 2.7135e-03 eta 0:13:39
epoch [5/20] batch [20/28] time 1.517 (1.888) data 0.001 (0.361) loss_x 0.1879 (0.2491) loss_u_aug 0.6644 (0.6722) loss_u_sty 1.0916 (1.0764) y_u_pred_acc_thre 0.9583 (0.9415) y_u_pred_acc_raw 0.6875 (0.6276) y_u_pred_keep_rate 0.2500 (0.2682) lr 2.7135e-03 eta 0:13:28
epoch [6/20] batch [10/28] time 1.496 (1.857) data 0.001 (0.338) loss_x 0.1518 (0.1708) loss_u_aug 0.6887 (0.6617) loss_u_sty 1.4304 (1.1069) y_u_pred_acc_thre 0.9286 (0.9454) y_u_pred_acc_raw 0.6250 (0.6260) y_u_pred_keep_rate 0.2917 (0.2807) lr 2.5607e-03 eta 0:12:41
epoch [6/20] batch [20/28] time 1.529 (1.868) data 0.001 (0.346) loss_x 0.1530 (0.1688) loss_u_aug 0.7503 (0.7226) loss_u_sty 0.8397 (1.0745) y_u_pred_acc_thre 0.9836 (0.9566) y_u_pred_acc_raw 0.6719 (0.6414) y_u_pred_keep_rate 0.3177 (0.2901) lr 2.5607e-03 eta 0:12:27
epoch [7/20] batch [10/28] time 1.545 (1.873) data 0.001 (0.347) loss_x 0.1275 (0.1364) loss_u_aug 0.5151 (0.6751) loss_u_sty 1.3216 (1.0845) y_u_pred_acc_thre 0.9359 (0.9510) y_u_pred_acc_raw 0.6771 (0.6635) y_u_pred_keep_rate 0.4062 (0.3245) lr 2.3817e-03 eta 0:11:55
epoch [7/20] batch [20/28] time 1.532 (1.869) data 0.001 (0.343) loss_x 0.1286 (0.1303) loss_u_aug 0.5833 (0.6745) loss_u_sty 0.8440 (1.0381) y_u_pred_acc_thre 0.9333 (0.9510) y_u_pred_acc_raw 0.6927 (0.6599) y_u_pred_keep_rate 0.3125 (0.3195) lr 2.3817e-03 eta 0:11:35
epoch [8/20] batch [10/28] time 1.501 (1.843) data 0.001 (0.318) loss_x 0.0975 (0.0998) loss_u_aug 0.6002 (0.7273) loss_u_sty 0.8839 (1.0079) y_u_pred_acc_thre 0.9865 (0.9335) y_u_pred_acc_raw 0.7031 (0.6589) y_u_pred_keep_rate 0.3854 (0.3375) lr 2.1810e-03 eta 0:10:52
epoch [8/20] batch [20/28] time 1.525 (1.870) data 0.001 (0.350) loss_x 0.1140 (0.0947) loss_u_aug 0.7542 (0.6961) loss_u_sty 1.1114 (0.9897) y_u_pred_acc_thre 0.9429 (0.9418) y_u_pred_acc_raw 0.6562 (0.6557) y_u_pred_keep_rate 0.3646 (0.3326) lr 2.1810e-03 eta 0:10:43
epoch [9/20] batch [10/28] time 1.504 (1.872) data 0.001 (0.353) loss_x 0.0957 (0.0838) loss_u_aug 0.6537 (0.6040) loss_u_sty 0.9872 (0.9766) y_u_pred_acc_thre 0.9403 (0.9470) y_u_pred_acc_raw 0.5781 (0.6443) y_u_pred_keep_rate 0.3490 (0.3401) lr 1.9635e-03 eta 0:10:10
epoch [9/20] batch [20/28] time 1.532 (1.880) data 0.001 (0.363) loss_x 0.0907 (0.0790) loss_u_aug 0.8123 (0.6187) loss_u_sty 1.0271 (0.9832) y_u_pred_acc_thre 0.9483 (0.9486) y_u_pred_acc_raw 0.6458 (0.6490) y_u_pred_keep_rate 0.3021 (0.3458) lr 1.9635e-03 eta 0:09:54
epoch [10/20] batch [10/28] time 1.515 (1.871) data 0.001 (0.353) loss_x 0.0855 (0.0647) loss_u_aug 0.6345 (0.7339) loss_u_sty 1.0288 (0.8741) y_u_pred_acc_thre 0.9054 (0.9408) y_u_pred_acc_raw 0.6458 (0.6323) y_u_pred_keep_rate 0.3854 (0.3698) lr 1.7347e-03 eta 0:09:17
epoch [10/20] batch [20/28] time 1.517 (1.867) data 0.001 (0.348) loss_x 0.0512 (0.0635) loss_u_aug 0.5444 (0.6636) loss_u_sty 1.0822 (0.8801) y_u_pred_acc_thre 0.9206 (0.9282) y_u_pred_acc_raw 0.6927 (0.6458) y_u_pred_keep_rate 0.3281 (0.3690) lr 1.7347e-03 eta 0:08:57
epoch [11/20] batch [10/28] time 1.528 (1.834) data 0.001 (0.312) loss_x 0.0616 (0.0532) loss_u_aug 0.5842 (0.5606) loss_u_sty 1.2908 (0.9462) y_u_pred_acc_thre 0.9651 (0.9323) y_u_pred_acc_raw 0.6875 (0.6536) y_u_pred_keep_rate 0.4479 (0.3818) lr 1.5000e-03 eta 0:08:15
epoch [11/20] batch [20/28] time 1.528 (1.846) data 0.001 (0.324) loss_x 0.0417 (0.0543) loss_u_aug 0.6596 (0.5975) loss_u_sty 0.7239 (0.9120) y_u_pred_acc_thre 0.9275 (0.9328) y_u_pred_acc_raw 0.6146 (0.6549) y_u_pred_keep_rate 0.3594 (0.3766) lr 1.5000e-03 eta 0:07:59
epoch [12/20] batch [10/28] time 1.509 (1.835) data 0.001 (0.315) loss_x 0.0488 (0.0469) loss_u_aug 0.6425 (0.5776) loss_u_sty 0.8632 (0.9254) y_u_pred_acc_thre 0.8533 (0.9188) y_u_pred_acc_raw 0.5885 (0.6490) y_u_pred_keep_rate 0.3906 (0.3755) lr 1.2653e-03 eta 0:07:24
epoch [12/20] batch [20/28] time 1.523 (1.861) data 0.001 (0.342) loss_x 0.0407 (0.0460) loss_u_aug 0.7664 (0.6297) loss_u_sty 0.8624 (0.9443) y_u_pred_acc_thre 0.9041 (0.9232) y_u_pred_acc_raw 0.6146 (0.6484) y_u_pred_keep_rate 0.3802 (0.3794) lr 1.2653e-03 eta 0:07:11
epoch [13/20] batch [10/28] time 1.525 (1.839) data 0.001 (0.312) loss_x 0.0435 (0.0407) loss_u_aug 0.4824 (0.5704) loss_u_sty 0.7711 (0.7995) y_u_pred_acc_thre 0.9200 (0.9304) y_u_pred_acc_raw 0.6354 (0.6490) y_u_pred_keep_rate 0.3906 (0.3990) lr 1.0365e-03 eta 0:06:33
epoch [13/20] batch [20/28] time 1.527 (1.872) data 0.000 (0.347) loss_x 0.0363 (0.0413) loss_u_aug 0.3826 (0.5869) loss_u_sty 1.0551 (0.8578) y_u_pred_acc_thre 0.9383 (0.9297) y_u_pred_acc_raw 0.6615 (0.6500) y_u_pred_keep_rate 0.4219 (0.3977) lr 1.0365e-03 eta 0:06:21
epoch [14/20] batch [10/28] time 1.530 (1.841) data 0.001 (0.319) loss_x 0.0416 (0.0403) loss_u_aug 0.8252 (0.6173) loss_u_sty 0.9759 (0.8258) y_u_pred_acc_thre 0.9241 (0.9334) y_u_pred_acc_raw 0.6146 (0.6651) y_u_pred_keep_rate 0.4115 (0.4188) lr 8.1901e-04 eta 0:05:42
epoch [14/20] batch [20/28] time 1.511 (1.849) data 0.001 (0.324) loss_x 0.0325 (0.0395) loss_u_aug 0.3920 (0.5912) loss_u_sty 0.9346 (0.8504) y_u_pred_acc_thre 0.9167 (0.9383) y_u_pred_acc_raw 0.6302 (0.6628) y_u_pred_keep_rate 0.3750 (0.4076) lr 8.1901e-04 eta 0:05:25
epoch [15/20] batch [10/28] time 1.525 (1.842) data 0.001 (0.318) loss_x 0.0341 (0.0358) loss_u_aug 0.4047 (0.5124) loss_u_sty 0.9532 (0.7951) y_u_pred_acc_thre 0.9474 (0.9435) y_u_pred_acc_raw 0.6771 (0.6656) y_u_pred_keep_rate 0.3958 (0.3927) lr 6.1832e-04 eta 0:04:50
epoch [15/20] batch [20/28] time 1.523 (1.881) data 0.001 (0.360) loss_x 0.0335 (0.0385) loss_u_aug 0.6921 (0.5451) loss_u_sty 0.8071 (0.7923) y_u_pred_acc_thre 0.9524 (0.9314) y_u_pred_acc_raw 0.7135 (0.6555) y_u_pred_keep_rate 0.4375 (0.3956) lr 6.1832e-04 eta 0:04:38
epoch [16/20] batch [10/28] time 1.505 (1.838) data 0.001 (0.316) loss_x 0.0389 (0.0352) loss_u_aug 0.4566 (0.4954) loss_u_sty 1.0713 (0.8504) y_u_pred_acc_thre 0.8721 (0.9332) y_u_pred_acc_raw 0.6302 (0.6620) y_u_pred_keep_rate 0.4479 (0.4109) lr 4.3934e-04 eta 0:03:58
epoch [16/20] batch [20/28] time 1.538 (1.847) data 0.001 (0.324) loss_x 0.0362 (0.0363) loss_u_aug 0.7731 (0.5186) loss_u_sty 0.8483 (0.8242) y_u_pred_acc_thre 0.9467 (0.9327) y_u_pred_acc_raw 0.6250 (0.6581) y_u_pred_keep_rate 0.3906 (0.4130) lr 4.3934e-04 eta 0:03:41
epoch [17/20] batch [10/28] time 1.513 (1.872) data 0.001 (0.345) loss_x 0.0283 (0.0349) loss_u_aug 0.6435 (0.6323) loss_u_sty 0.6336 (0.8258) y_u_pred_acc_thre 0.9412 (0.9239) y_u_pred_acc_raw 0.6146 (0.6490) y_u_pred_keep_rate 0.4427 (0.4068) lr 2.8647e-04 eta 0:03:10
epoch [17/20] batch [20/28] time 1.537 (1.878) data 0.001 (0.350) loss_x 0.0298 (0.0333) loss_u_aug 0.5725 (0.6230) loss_u_sty 0.7180 (0.8161) y_u_pred_acc_thre 0.9620 (0.9272) y_u_pred_acc_raw 0.6927 (0.6529) y_u_pred_keep_rate 0.4115 (0.4143) lr 2.8647e-04 eta 0:02:52
epoch [18/20] batch [10/28] time 1.516 (1.829) data 0.001 (0.293) loss_x 0.0382 (0.0329) loss_u_aug 0.4246 (0.5528) loss_u_sty 0.5696 (0.7197) y_u_pred_acc_thre 0.9241 (0.9161) y_u_pred_acc_raw 0.6354 (0.6604) y_u_pred_keep_rate 0.4115 (0.4313) lr 1.6349e-04 eta 0:02:15
epoch [18/20] batch [20/28] time 1.553 (1.865) data 0.001 (0.329) loss_x 0.0338 (0.0346) loss_u_aug 0.5787 (0.5840) loss_u_sty 0.8937 (0.7569) y_u_pred_acc_thre 0.9625 (0.9290) y_u_pred_acc_raw 0.6875 (0.6669) y_u_pred_keep_rate 0.4167 (0.4263) lr 1.6349e-04 eta 0:01:59
epoch [19/20] batch [10/28] time 1.507 (1.856) data 0.001 (0.329) loss_x 0.0332 (0.0334) loss_u_aug 0.2799 (0.5550) loss_u_sty 0.9353 (0.8264) y_u_pred_acc_thre 0.9726 (0.9377) y_u_pred_acc_raw 0.6458 (0.6568) y_u_pred_keep_rate 0.3802 (0.4104) lr 7.3415e-05 eta 0:01:25
epoch [19/20] batch [20/28] time 1.516 (1.865) data 0.001 (0.340) loss_x 0.0339 (0.0328) loss_u_aug 0.4457 (0.5345) loss_u_sty 0.8383 (0.8216) y_u_pred_acc_thre 0.9681 (0.9319) y_u_pred_acc_raw 0.6927 (0.6596) y_u_pred_keep_rate 0.4896 (0.4219) lr 7.3415e-05 eta 0:01:07
epoch [20/20] batch [10/28] time 1.521 (1.859) data 0.001 (0.335) loss_x 0.0287 (0.0316) loss_u_aug 0.4372 (0.5439) loss_u_sty 1.1039 (0.8419) y_u_pred_acc_thre 0.9079 (0.9260) y_u_pred_acc_raw 0.6979 (0.6615) y_u_pred_keep_rate 0.3958 (0.4010) lr 1.8467e-05 eta 0:00:33
epoch [20/20] batch [20/28] time 1.510 (1.856) data 0.001 (0.335) loss_x 0.0600 (0.0336) loss_u_aug 0.4489 (0.5003) loss_u_sty 0.5699 (0.8317) y_u_pred_acc_thre 0.9405 (0.9337) y_u_pred_acc_raw 0.6510 (0.6604) y_u_pred_keep_rate 0.4375 (0.4109) lr 1.8467e-05 eta 0:00:14
Checkpoint saved to output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5/G/model.pth.tar-20
Checkpoint saved to output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5/C/model.pth.tar-20
Finish training
Evaluate on the *test* set
=> result
* total: 4,357
* correct: 2,995
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 66.5%
Checkpoint saved to output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5/G/model.pth.tar-20
Checkpoint saved to output/20230814/fact_mixstyle_fea_gaosi2_10seed/ssdg_officehome/nlab_975/StyleMatch/resnet18/v1/real_world/seed5/C/model.pth.tar-20
Elapsed: 0:19:16
